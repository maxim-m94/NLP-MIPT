{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  \\\n",
       "0  0   \n",
       "1  0   \n",
       "2  1   \n",
       "3  0   \n",
       "4  0   \n",
       "\n",
       "                                                                                                                                                          Text  \n",
       "0                                              Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
       "1                                                                                                                                Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's  \n",
       "3                                                                                                            U dun say so early hor... U c already then say...  \n",
       "4                                                                                                Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./smsspamcollection/SMSSpamCollection\", delimiter='\\t', names=(\"Y\", \"Text\"))\n",
    "data.Y[data.Y == 'ham'] = 0\n",
    "data.Y[data.Y == 'spam'] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86593682699210339"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Y.value_counts()[0] * 1.0 /(data.Y.value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fold_res= 0.93 std_fold_res= 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer()#ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(data.Text)\n",
    "\n",
    "\n",
    "cls = LogisticRegression()\n",
    "res = cross_val_score(cls, X, data.Y.astype(int), scoring=\"f1\", cv=10)\n",
    "print \"mean_fold_res=\", \"%.2f\"%np.mean(res), \"std_fold_res=\", \"%.2f\"%np.std(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of \\\n",
    "3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "\"Have you visited the last lecture on physics?\",\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have \\\n",
    "all materials! Only 99$\",\n",
    "\"Only 99$\"]\n",
    "X_target = vectorizer.transform(target_data)\n",
    "cls.fit(X, data.Y.astype(int))\n",
    "cls.predict(X_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "ngram_range =  (1, 1) res= 0.93\n",
      "ngram_range =  (2, 2) res= 0.82\n",
      "ngram_range =  (3, 3) res= 0.73\n",
      "ngram_range =  (1, 3) res= 0.93\n"
     ]
    }
   ],
   "source": [
    "print \"Logistic Regression:\"\n",
    "for ngram_range in [(1,1), (2,2), (3,3), (1,3)]:\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)#ngram_range=(1,2)\n",
    "    X = vectorizer.fit_transform(data.Text)\n",
    "    cls = LogisticRegression()\n",
    "    res = cross_val_score(cls, X, data.Y.astype(int), scoring=\"f1\", cv=10)\n",
    "    print \"ngram_range = \", ngram_range,  \"res=\", \"%.2f\"%np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "ngram_range =  (1, 1) res= 0.93\n",
      "ngram_range =  (2, 2) res= 0.65\n",
      "ngram_range =  (3, 3) res= 0.38\n",
      "ngram_range =  (1, 3) res= 0.89\n"
     ]
    }
   ],
   "source": [
    "print \"Multinomial Naive Bayes\"\n",
    "for ngram_range in [(1,1), (2,2), (3,3), (1,3)]:\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)#ngram_range=(1,2)\n",
    "    X = vectorizer.fit_transform(data.Text)\n",
    "    cls = MultinomialNB()\n",
    "    res = cross_val_score(cls, X, data.Y.astype(int), scoring=\"f1\", cv=10)\n",
    "    print \"ngram_range = \", ngram_range,  \"res=\", \"%.2f\"%np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, качество при переходе от количественных признаков к tf*idf падает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with tf*idf features:\n",
      "ngram_range =  (1, 1) res= 0.85\n",
      "ngram_range =  (2, 2) res= 0.34\n",
      "ngram_range =  (3, 3) res= 0.17\n",
      "ngram_range =  (1, 3) res= 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "print \"Logistic Regression with tf*idf features:\"\n",
    "for ngram_range in [(1,1), (2,2), (3,3), (1,3)]:\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range)#ngram_range=(1,2)\n",
    "    X = vectorizer.fit_transform(data.Text)\n",
    "    cls = LogisticRegression()\n",
    "    res = cross_val_score(cls, X, data.Y.astype(int), scoring=\"f1\", cv=10)\n",
    "    print \"ngram_range = \", ngram_range,  \"res=\", \"%.2f\"%np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше попробуем побороться за качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC c= 50 \tres= 0.90\n",
      "SVC c= 500 \tres= 0.94\n",
      "SVC c= 10000 \tres= 0.94\n",
      "SVC c= 50000 \tres= 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data.Text)\n",
    "for c in [50, 500, 10000, 50000]:\n",
    "    cls = SVC(C=c,)\n",
    "    res = cross_val_score(cls, X, data.Y.astype(int), scoring=\"f1\", cv=10)\n",
    "    print  \"SVC\", \"c=\", c, \"\\tres=\", \"%.2f\"%np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB \t res= 0.71\n"
     ]
    }
   ],
   "source": [
    "cls = GaussianNB()\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data.Text)\n",
    "res = cross_val_score(cls, X.toarray(), data.Y.astype(int), scoring=\"f1\", cv=10)\n",
    "print  \"GaussianNB\", \"\\t res=\", \"%.2f\"%np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "stemmer = PorterStemmer()#SnowballStemmer(\"english\")\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def __init__(self, stemmer):\n",
    "        super(StemmedCountVectorizer, self).__init__()\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc:(self.stemmer.stem(w) for w in analyzer(doc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed SVC\n",
      "\tTf Idf: res= 0.95 std= 0.02\n",
      "\tCount:res= 0.94 std= 0.02\n",
      "Stemmed LogisticRegression\n",
      "\tTf Idf: res= 0.95 std= 0.02\n",
      "\tCount:res= 0.94 std= 0.02\n"
     ]
    }
   ],
   "source": [
    "def get_stemmed_score(clf, name):\n",
    "    stem_vectorizer = StemmedCountVectorizer(stemmer)\n",
    "    text_clf_tfidf = Pipeline([('vect', stem_vectorizer), ('tfidf', TfidfTransformer()), ('clf', clf) ])\n",
    "    text_clf = Pipeline([('vect', stem_vectorizer), ('clf', SVC(kernel='linear', C=500)) ])\n",
    "\n",
    "    print \"Stemmed \" + name\n",
    "    score = cross_val_score(text_clf_tfidf, data.Text, data.Y.astype(int), scoring='f1', cv=10)\n",
    "    print \"\\t\", \"Tf Idf:\", \"res=\", \"%.2f\"%np.mean(score), \"std=\",\"%.2f\"%np.std(score)\n",
    "    score = cross_val_score(text_clf, data.Text, data.Y.astype(int), scoring='f1', cv=10)\n",
    "    print '\\t', \"Count:\" \"res=\",\"%.2f\"%np.mean(score), \"std=\",\"%.2f\"%np.std(score)\n",
    "\n",
    "get_stemmed_score(SVC(kernel='linear', C=500), \"SVC\")\n",
    "get_stemmed_score(LogisticRegression(C=500), \"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество при оптимизации \"f1\"-метрики у меня получилось 0.95. Конечно, хотелось сразу попробовать SVM, он дал результат чуть лучше, потом, конечно, простемить входные данные, стало заметно получше. Стоп-слова я не стал пробовать, потому что интуитивно кажется, это тут только навредит, хотя, конечно, это не аргумент)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
